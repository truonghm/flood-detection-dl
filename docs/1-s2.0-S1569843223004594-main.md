Contents lists available at ScienceDirect

International Journal of Applied Earth Observation and
Geoinformation

journal homepage: www.elsevier.com/locate/jag

Unsupervised flood detection on SAR time series using variational
autoencoder
Ritu Yadav a,∗, Andrea Nascetti a, Hossein Azizpour b, Yifang Ban a
a Division of Geoinformatics, Sweden
b Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden

A R T I C L E I N F O

A B S T R A C T

Keywords:
SAR
Time series
Contrastive learning
VAE
Unsupervised change detection
Flood detection

In this study, we propose a novel unsupervised Change Detection (CD) model to detect flood extent using
Synthetic Aperture Radar (SAR) time series data. The proposed model is based on a spatiotemporal variational
autoencoder, trained with reconstruction and contrastive learning techniques. The change maps are generated
with a proposed novel algorithm that utilizes differences in latent feature distributions between pre-flood and
post-flood data. The model is evaluated on nine different flood events by comparing the results with reference
flood maps collected from the Copernicus Emergency Management Services (CEMS) and Sen1Floods11 dataset.
We conducted a range of experiments and ablation studies to investigate the performance of our model. We
compared the results with existing unsupervised models. The model achieved an average of 70% Intersection
over Union (IoU) score which is at least 7% better than the IoU from existing unsupervised CD models. In the
generalizability test, the proposed model outperformed supervised models ADS-Net (by 10% IoU) and DAUSAR
(by 8% IoU), both trained on Sen1Floods11 and tested on CEMS sites. Our implementation will be available
here https://github.com/RituYadav92/CLVAE-Unsupervised_Change_Detection_TimeSeriesSAR.

1. Introduction

Human civilization has an increasingly powerful influence on the
Earth system. Affected by climate and land use changes, natural dis-
asters such as flooding have increased in recent years (CRED, 2022).
On-ground evaluations of large-scale floods can be time-consuming and
risky, primarily due to unfavorable weather conditions and collapsed
transportation systems. However, Earth observations obtained from
satellites offer a solution by providing quick access to information in
vast geographical areas. The data can be used in detecting and mapping
flood extent. Moreover, leveraging accurate and reliable automatic CD
models enables near-real-time identification of flood extent, facilitating
swift and efficient disaster management.

Sentinel satellites, such as Sentinel-1 Synthetic Aperture Radar
(SAR) and Sentinel-2 MultiSpectral Instrument (MSI) are widely used
for mapping, and monitoring tasks because of their openly accessible
good spatial and temporal resolution data. Sentinel-2 offers rich multi-
spectral data capturing detailed information about the Earth’s surface.
However, floods are highly correlated with clouds, posing a challenge
to Sentinel-2 as clouds can obstruct a significant portion of the view.
Additionally, cloud shadows can be mistaken for water by algorithms,
further complicating the analysis. In contrast, Sentinel-1, a radar satel-
lite, operates in the microwave band, allowing it to penetrate through

clouds and capture dielectric properties of the surface day or night,
regardless of weather conditions. This makes Sentinel-1 the preferred
choice for flood mapping in numerous research studies (Anusha and
Bharathi, 2020).

In general, there are three common flood mapping approaches based
on the number of dates, i.e., single(uni-temporal), dual (bitemporal)
and multiple dates(multi-temporal). In the first case, one image is used
at a time to detect floods which essentially is water surface mapping.
In the second case usually CD approaches are performed, while in the
third case a time series can be used for advanced temporal analysis
in different approaches. Most of the existing SAR based flood detec-
tion approaches in remote sensing are either based on uni-temporal
data (Boryan et al., 2018; Yadav et al., 2022b) or bitemporal data (Zhao
et al., 2023; Yadav et al., 2022a). The output flood map from these
approaches can be inaccurate due to different seasonal effects in the
reference image. However, utilizing time series data helps in reducing
such seasonal noise (Schlaffer et al., 2015). By considering multiple
observations over time, the impact of seasonal variations is better
accounted for, resulting in more reliable and precise flood mapping
outcomes.

There are few classical pixel-wise methods to map floods using
multi-temporal images (Cian et al., 2018; Karamvasis and Karathanassi,

∗ Corresponding author.

E-mail address: rituy@kth.se (R. Yadav).

https://doi.org/10.1016/j.jag.2023.103635
Received 5 September 2023; Received in revised form 13 December 2023; Accepted 15 December 2023

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)103635Availableonline22December20231569-8432/©2023TheAuthors.PublishedbyElsevierB.V.ThisisanopenaccessarticleundertheCCBY-NC-NDlicense(http://creativecommons.org/licenses/by-nc-nd/4.0/).R. Yadav et al.

2021), but these methods are largely dependent on handcrafted fea-
tures, manual threshold adjustment and do not leverage rich spatial
information between neighboring pixels. Such methods often have limi-
tations in capturing the complex and high-dimensional nature of remote
sensing data (Zhou et al., 2018). Deep learning (DL) methods have
gained new achievements due to their powerful representation learning
and discriminative ability (Asokan and Anitha, 2019). Compared to
classical methods, DL methods can easily learn complex patterns in
larger spatial contexts and incorporate spatiotemporal features of time
series data without relying on handcrafted features (Zhou et al., 2018;
Yan et al., 2020).

Deep learning CD methods in remote sensing are predominantly su-
pervised, and their effectiveness heavily relies on having access to local
reference data for training. When applied to unseen regions, they often
produce unsatisfactory results due to limited generalization capabilities
across different regions, primarily caused by domain shift between the
training and deployment data (Tuia et al., 2016). Obtaining a large
amount of annotated data that covers morphological variations across
different regions and accurately represents flood extent (change), is
expensive, time-consuming, and requires domain expertise. To address
this challenge, unsupervised models are preferred, as they encapsulate
robust generalization properties (Ren et al., 2020). With unsupervised
learning, models can be trained on abundant unlabeled Earth obser-
vation data that is readily available. This not only eliminates the
labeling cost but also enhances the model’s generalizability compared
to supervised models (Ržička et al., 2021).

In this work, our aim is to develop a robust unsupervised CD model
for accurate flood mapping. We proposed using rich temporal and
spatial features from the Sentinel-1 time series SAR data for the task. To
the best of our knowledge, there is no previous unsupervised DL-based
work designed specifically for flood mapping using Sentinel-1 SAR data
that explicitly exploits pixel-wise time series signal patterns.

2. Related work

In recent years, DL models in Earth observation have received sig-
nificant attention. More recently, unsupervised DL models are proposed
for CD on remote sensing data such as Liu et al. (2016) proposed
a model to detect pixel-wise difference maps between heterogeneous
and homogeneous combinations of SAR and optical images. The model
used speckle and Gaussian noise models coupled within a small con-
volutional network. The noise models are coupled with the help of
a manual parameter that needs adjustment when applied to different
sites. Zhan et al. (2018) proposed a SCCN model to detect changes
between SAR and optical images. The model used a small Denoising Au-
toEncoder (DAE) to extract image features and classify them as change
or no change using a fuzzy C-means clustering algorithm (Krinidis and
Chatzis, 2010). The authors assumed that SAR and optical images have
similar statistical distribution properties. Niu et al. (2018) proposed
using a conditional generative adversarial network (cGAN), where the
input images are brought into a de-noised form to detect changes.

In past few years, unsupervised learning techniques like SimCLR
(Chen et al., 2020b), MoCo (Chen et al., 2020a), BYOL (Grill et al.,
2020) and DeepCluster (Caron et al., 2018) has shown tremendous suc-
cess in computer vision tasks. SimCLR and MoCo proposed contrastive
learning from ‘positive pairs’ (augmented version of the same image)
and ‘negative pairs’ (augmented version of a different image). These
models need careful treatment for negative pairs by relying on large
batches or memory banks. The need for negative pairs was eliminated
by BYOL, relying on learning from positive pairs. DeepCluster is a
clustering model that jointly learns the parameters of a neural network
and cluster assignments of the resulting features.

Dong et al. (2021a) used DeepCluster technique to implement unsu-
pervised clustering with CNN to learn cluster-friendly feature represen-
tations of remote sensing SAR data. This model generates pseudo labels
and uses them to supervise the training. Another work (Saha et al.,

2021) also used DeepCluster along with contrastive learning to train
a siamese segmentation network. The model was trained using pseudo
labels from deep clustering and contrastive learning strategy. These
pseudo labels contain ‘‘label noise’’ which subsequently affects network
optimization and accuracy (Wang et al., 2022a,b). Code Aligned Au-
toencoder (CAA) (Luppino et al., 2022) proposed an encoder–decoder
network that learns features from cross-modality with the help of
contrastive learning. The model merged features from the two modal-
ities and produced a change map by calculating the difference image
between the input pre-image and the output generated by the network.
The binary change map was prepared by applying manual thresholding.
These unsupervised models are tested on scenes with limited spatial
complexity and often fail with the increased complexity of the geo-
graphical landscape (Lv et al., 2022). Moreover, none of these models
explore rich spatiotemporal information of time series data. Further-
more, the performance of some of the mentioned models like Zhan et al.
(2018), Luppino et al. (2022) depends on manual thresholding. A recent
work, RaVAEn (Ržička et al., 2021) proposed to train a variational
autoencoder on individual images from the time series and utilized a
distance metric on the latent parameters to detect changes between two
optical (Sentinel-2) images. The authors evaluated this model on four
CD tasks, including flood detection. However, detecting floods with
optical sensors might not be reliable due to associated clouds. The
authors proposed to train on individual images from the time series
and did not benefit from the spatiotemporal features of the time series.
Moreover, the output change maps are not detailed as the maps are
patch-wise (size 32 × 32 pixels) and not pixel-wise. Some of the samples
are demonstrated in qualitative analysis 8 and 9.

Inspired by the recent advances in unsupervised DL techniques, we
approached the change detection problem in a fully self-supervised
manner. We introduce a generative network for CD on Sentinel-1
SAR time series data. The proposed model is named as Contrastive
ConvLSTM Variational AutoEncoder (CLVAE). The key contributions of
this work are as follows.

1. CLVAE gains its ability predominantly from the strong latent
representations learned by the probabilistic reconstruction ar-
chitecture of the variational autoencoder. We show how the
latent parameters from the trained encoder can be employed to
generate change maps. See Section 4.3 and framework 4.

2. We exploited the rich SAR time series information by adopt-
ing a convolutional long short-term memory in the proposed
architecture. The network is further empowered with skip con-
nections between the encoder and decoder to improve network
optimization.

3. The proposed CD network is trained in a self-supervised manner.
Along with KL divergence and reconstruction loss, the network
is trained using contrastive learning where layers can learn to
reconstruct SAR input so well that they can identify changes in
patches. We followed the contrastive learning idea from MoCo
and simplified it for the remote sensing CD task.

4. The proposed training network is lightweight with only 576,395

total parameters, making them easier to test and deploy.

3. Data and study area

The dataset consists of Sentinel-1 SAR pre-flood images, post-flood
images and reference maps covering nine flood events from Slovakia,
Somalia, Spain, Bolivia, Mekong, Bosnia, Australia, Scotland and Ger-
many. Study sites are marked in the map (Fig. 1). The pre-flood images
are used for network training, while both pre-flood and post-flood
images are used for inference. The reference maps are used for the
evaluation. Sentinel-1 SAR pre-flood and post-flood images were down-
loaded from Google Earth Engine (GEE) and corresponding reference
maps were collected from the Sen1Floods11 (Bonafilia et al., 2020) test
dataset and Copernicus Emergency Management Service (CEMS, 2022).
The detailed data specifications are given in Table 1. The reference
map, Sentinel-1 SAR data collection process and data pre-processing
steps are explained in the following subsections.

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036352R. Yadav et al.

Fig. 1. Overview of study sites. Colored dots represent tile locations, and numbers are the references given to each tile. The red dots represent the Sen1Floods11 sites, and the
green dots represent the CEMS sites. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

Table 1
Flood Event Metadata. ‘Ref. Source’ contains the satellite sources and ‘Ref. Date’ is the post-flood image date used to create the reference maps.
‘S1 Post Date’ is the date of the Sentinel-1 post-flood image used in this study.

ID

Site

Sen1Floods11

Ref. date

Ref. source

S1 Post date

Orbit

Rel. orbit

Area (Km2)

1
2
3
4
5

Slovakia
Somalia
Spain
Bolivia
Mekong

2020/10/20
2020/05/07
2019/09/17
2018/02/15
2018/08/05

Sentinel-1/2
Sentinel-1/2
Sentinel-1/2
Sentinel-1/2
Sentinel-1/2

Copernicus Emergency Management Service

6
7
8
9

Bosnia
Australia
Scotland
Germany

2022/04/03
2022/03/31
2022/11/18
2022/02/03

Sentinel-2, RADARSAT2
ESRI, COSMO-SkyMed
ESRI, Sentinel-1
Sentinel-2, Sentinel-1

2020/10/20
2020/05/07
2019/09/17
2018/02/15
2018/08/05

2022/04/06
2022/03/31
2022/11/18
2021/02/03

73
116
110
156
26

51
147
30
139

ASC
ASC
DES
DES
ASC

DES
DES
ASC
DES

2.5
2.5
2.5
5
5

5
7.5
5
10

3.1. Reference data

3.2. Sentinel-1 SAR data

Sen1Floods11 Dataset consists of Sentinel-1 SAR and Sentinel-
2 MSI post-flood images from 11 different flood events that cover
a wide variety of geographical areas. In total, there are 446 non-
overlapped tiles of size 512 × 512 pixels each. The data set is at
a ground resolution of 10 meters and each sample is composed of
two bands VV (vertical transmit, vertical receive) and VH (vertical
transmit, horizontal receive) polarization. The reference flood maps
are hand-labeled by experts using information from Sentinel-1 SAR
and Sentinel-2 MSI data. Each pixel in the reference is classified into
three classes, 0, 1, and −1 representing background, water, and missing
data respectively. Wherever there is a cloudy pixel in Sentinel-2, the
corresponding pixel in reference is marked as missing data, that is, -1.
Since there is a high correlation between floods and clouds, the number
of missing pixels in the reference data is significantly high. We avoid
the uncertainty of flood extent in the missing data area and target com-
plete flood extent evaluation by selecting sites with no missing data in
reference.

Copernicus Emergency Management Service (CEMS) is one of
the six worldwide services for early warning, monitoring and mapping
of different natural and man-made disasters. We added four recent
(2022) flood events to the dataset, Mostar (Bosnia), Coraki (Australia),
Aberdeen (Scotland) and Western Rhine river (Germany). The reference
flood maps were downloaded from the CEMS website. These reference
maps were derived using a semi-automatic approach on pre and post-
flood satellite images. Table 1 contains the data specification for the
reference maps.

The Sentinel-1 SAR data was downloaded from GEE. The Sentinel-
1 mission captures C-band SAR images at 10 meter resolution with
dual polarization (HH+HV and VV+VH). Before ingesting to GEE,
all Sentinel-1 images undergo preprocessing to obtain ground range
detected images using the Sentinel-1 Toolbox. Pre-processing steps in-
clude the removal of thermal noise, radiometric calibration, and terrain
correction. In addition, the backscatter coefficients are converted to
decibels using logarithmic scaling (10 log10 𝑥). The Sentinel-1 data in
GEE are dual-band (VV+VH) scenes acquired in interferometric wide
swath mode within a specified period, orbit, and location.

Sen1Floods11 Dataset The post-flood images are already avail-
able in the Sen1Floods11 dataset. To obtain the required pre-flood
images: First, the geometry, relative orbit, and passing orbit details
are extracted from the available post-flood images. Next, using the
extracted geometry and orbit criteria, a time series of Sentinel-1 images
is downloaded within a four-month window preceding the date of the
flood event. From this collection of Sentinel-1 images, eight pre-flood
images (pre-images) are selected for each flood event. Further data
specifications for each site are given in Table 1. We also collected
data for pre-training the reconstruction network. The same process is
followed to collect four pre-flood time series images corresponding to
100 random patches from the Sen1Floods11 dataset.

Copernicus Emergency Management Service (CEMS) For each
flood event, multiple 512 × 512 pixels tiles covering urban and sur-
rounding agricultural areas are selected. For each reference flood map
tile, one post-flood image (dates in Table 1) and eight pre-flood images
are selected, with the check that both pre-and post-flood images have
the same relative orbit, and passing orbit.

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036353R. Yadav et al.

Fig. 2. Overview of the proposed Network Architecture for unsupervised CD. The network is trained on small 16 × 16 × 2 patches to learn the distribution of the small region
at a time.

Fig. 3. Unsupervised training pipeline overview. The model is trained on the reconstruction task using contrastive learning.

3.3. Data preprocessing

Before exporting Sentinel-1 SAR data from GEE, all scenes were
filtered on the basis of ascending (ASC) and descending (DES) passes
because there is a strong influence of the incidence angle on the
backscatter coefficient. It is ensured that the orbit pass (orbit) and
relative orbit (Rel. Orbit) of all pre and post-flood images are consistent.
Subsequently, the VV and VH channels are clipped within the range of
(−23, 0) dB and (−28, -5) dB, respectively and normalized to the range
of [0, 1].

4. Methodology

4.1. Proposed network architecture

The network shown in Fig. 2 is composed of an encoder module,
intermediate layers, and a decoder module. The encoder consists of a
convolutional LSTM layer, two residual blocks, a GlobalAveragePool-
ing3D layer, and a dense layer. The convolutional LSTM layer takes
a time series of input patches and extracts both temporal and spatial
features. Each residual block has three sets of 3D convolutional layer
and batch normalization layer. All convolutional layers used kernel of

size 3 and stride 2. The residual block is followed by a GlobalAverage-
Pooling3D layer, which calculates the spatial average value for each
channel and reduces the dimensionality effectively. At last, a bottleneck
dense layer of 8 channels is added. The output of the dense layer
passes through two intermediate layers, which are dense layers of a
size equivalent to the dimensionality of the latent space (128). These
two dense layers outputs mean (𝜇) and log-variance (𝜎) values of the
latent distribution.

The 𝜇 and 𝜎 outputs are 1D vectors used to sample a latent vector
𝑧 ∼  (𝜇, 𝜎) with the help of reparameterization trick (Kingma and
Welling, 2013) for the forward pass to remain differentiable w.r.t. to
𝜇 and 𝜎. The decoder takes sampled 𝑧 as input and passes through a
dense layer. These features are then fed into three sets of transpose
convolution and batch normalization layers to reconstruct the input.
For transpose convolution Conv3DTranspose layer is implemented with
kernel size 3 and stride 2.

Furthermore, the decoder network’s capacity is improved by em-
ploying cross-connections from the encoder network. Note that such
skip layers deviate from the standard VAE by having the reconstruction
conditioned not only on the latent representation but also on inter-
mediate representations of the encoder. We found this change to be
helpful. Apart from improving the decoder’s reconstruction capability,
skip connection also help VAE in learning better representation and
leads to better optimization (Cai et al., 2019; Dai et al., 2020).

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036354R. Yadav et al.

Fig. 4. Inference pipeline to generate pixel-wise binary change map using algorithm 1.

4.2. Training pipleline

An overview of the training pipeline is shown in Fig. 3. The pro-
posed network is placed in parallel forming two streams where the
encoders share weights. The inputs are time series patches 𝑃 1 and 𝑃 2
from different locations. During training, the network’s objective is to
reconstruct these inputs while progressively increasing the dissimilarity
between the reconstructed outputs from the two streams.

The network is optimized using three unsupervised loss functions:
a reconstruction loss (𝐿𝑅𝑒𝑐𝑜𝑛), a Kullback–Leibler (𝐾𝐿) divergence
loss (Kingma and Welling, 2013) (𝐿𝐾𝐿), and a contrastive loss (Hadsell
et al., 2006) (𝐿𝐶𝑜𝑛𝑡𝑟𝑎𝑠𝑡). Note that the first two losses constitute the
standard VAE objective. The reconstruction loss encourages the latent
representation to contain adequate input information for an accurate
reconstruction. The 𝐾𝐿 divergence loss pushes the latent distribution
to be decorrelated and brings it closer to a standard Gaussian.

The contrastive loss ensures diversity in the reconstructions of
the two independent patches 𝑃 1 and 𝑃 2. Since the patches are from
different locations capturing distinct areas, they are expected to fre-
quently contain dissimilar features. Incorporating the contrastive loss
enables the network to learn latent representations capable of distin-
guishing features between separate patches. Additionally, it facilitates
the learning of uniformly distributed noise, resulting in a denoising
architecture (Dong et al., 2021b). It is well known that SAR data
contains peculiar speckle noise and tackling such noise in a change
detection task is one of the major challenges in remote sensing (Wang
et al., 2022a). Therefore, adding a denoising ability to the architecture
holds significant importance.

The combined objective of the training network is given in the
below equation where 𝐿𝐾𝐿 is the 𝐾𝐿 divergence loss, 𝐿𝑅𝑒𝑐𝑜𝑛 is the
binary cross entropy loss as reconstruction loss and 𝐿𝐶𝑜𝑛𝑡𝑟𝑎𝑠𝑡 is the
cosine similarity loss as contrastive loss. Parameters 𝛼, and 𝛽 are the
weight parameter to prioritize losses.

𝐿𝑇 𝑜𝑡𝑎𝑙

= 𝛼 ∗ [𝐿𝐾𝐿(𝜇𝑃 1, 𝜎𝑃 1, 𝑁(0, 1))
+ 𝐿𝐾𝐿(𝜇𝑃 2, 𝜎𝑃 2, 𝑁(0, 1))]
+ 𝛽 ∗ [𝐿𝑅𝑒𝑐𝑜𝑛(𝑃 1,
+ (1 − 𝛼 − 𝛽) ∗ 𝐿𝐶𝑜𝑛𝑡𝑟𝑎𝑠𝑡( ̂𝑃 1,

̂𝑃 1) + 𝐿𝑅𝑒𝑐𝑜𝑛(𝑃 2,

̂𝑃 2)

̂𝑃 2)]

(1)

4.3. Inference pipeline

Importantly, the proposed network is trained solely on pre-event
time series, allowing it to adapt its parameters to the feature distri-
bution of pre-event data. Based on this, we make the assumption that
the latent variables for a patch 𝑃 1 will undergo a significant change
when affected by an extreme event. This leads us to propose an effective
mechanism for detecting changes. The proposed inference pipeline is
illustrated in Fig. 4.

From the trained network, the learned distribution can be retrieved
as 1D vectors mean 𝜇 and log-variance 𝜎. The variance is obtained
by taking the exponent of log-variance. When the pre-flood and post-
flood patches go through corresponding trained encoders 𝑒1(.) and 𝑒2(.),
the latent variables obtained are (𝜇1, 𝜎1) and (𝜇2, 𝜎2) respectively. To
estimate the divergence between the two latent distributions, we pro-
pose to use Cosine Distance (CosD) function given in Eq. (2). Different
functions are tested (5.5) before selecting CosD as a distance measure.

𝐶𝑜𝑠𝐷(𝜇1, 𝜇2) = 1 −

𝜇1
‖𝜇1‖

.

𝜇2
‖𝜇2‖

(2)

The value of CosD ranges between 0 and 2, where 0 indicates identical
vectors (positive correlation), 2 indicates opposite vectors (negative
correlation) and 1 indicates orthogonal vectors (no correlation). To
derive a binary change map (BIN_CMAP) from the CosD values, we used
a threshold (TH) i.e., CosD greater than 0.5 is categorized as change
otherwise no change.

Unlike training, inference inputs (pre and post-flood images) are
from the same location. The process of generating a change map
(COSINE_DIFF_MAP) from the inputs is outlined in the algorithm 1. It
is similar to applying kernel in convolutional operation. Just like CNN,
input images are first padded to preserve boundary information. We use
mirror padding with a length of 8 pixels. Input patches are generated
with stride one and processed through an encoder with a batch of size
512. On the output distribution, CosD is applied as a kernel that moves
like a sliding window with a stride one, resulting in a pixel-wise change
map i.e., COSINE_DIFF_MAP. At last, a threshold (TH) is applied to
derive a binary change map (BIN_CMAP).

4.4. Network implementation and configuration details

Each input SAR image contains two channels: VV and VH. The train-
ing data is augmented using two geometric (flips and rotation) and two
non-geometric (Gaussian blur, gammaContrast) augmentation methods,
proven to improve the performance of CNNs in remote sensing scene
classification (Yu et al., 2017). The Gaussian blur is implemented
with 3 × 3 kernel and gammaContrast with a range (0.25, 2.0). Flips
are applied left–right with a probability of 0.5 and up-down with a
probability of 0.2. Rotation is implemented randomly between −90
and 90 degrees. The positive pairs are augmented with non-geometric
augmentation and negative pairs are augmented with both geometric
and non-geometric augmentation.

The best results are achieved with input patches of size 16 × 16,
a time series of length 4 and a network architecture with two down-
sampling residual blocks. A comparison of different configurations is
shown in Section 5.5. After experimenting with multiple combinations,
the weight parameters 𝛼 and 𝛽 of the objective function (1) are set to
0.1 and 0.7 respectively.

The training network is lightweight with 576,395 trainable pa-
rameters. The network is pre-trained on SAR pre-images collected

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036355R. Yadav et al.

Algorithm 1: Binary Change Map Inference.

Input: Time series pre flood images of length n(PRE_IMAGES), post

flood image(POST_IMAGE), PATCH_SIZE = n×16×16×2,
PAD_SIZE= 8, TH, MODEL
Output: Binary change map BIN_CMAP.

1 Pad PRE_IMAGES and POST_IMAGE using reflect mode and

PAD_SIZE.

2 PRE_EVENT_DATA = stack all PRE_IMAGES.
3 POST_EVENT_DATA = stack POST_IMAGE n times.
4 PRE_PATCH = patches from PRE_EVENT_DATA of patchsize and

stride 1.

5 POST_PATCH = patches from POST_EVENT_DATA of patchsize and

stride 1.

6 for PRE_PATCH and POST_PATCH do

7

8

9

PRE_MEAN, PRE_STD =

MODEL.encoder1.predict(PRE_PATCH)

POST_MEAN, POST_STD =

MODEL.encoder2.predict(POST_PATCH)

Calculate CosD between PRE_MEAN and POST_MEAN.

10 From patch-wise CosD get the change map COSINE_DIFF_MAP.
11 Apply threshold of TH to get binary change map BIN_CMAP=

COSINE_DIFF_MAP>TH

corresponding to Sen1Floods11 floods, which helps model to learn the
reconstruction of SAR time series. The network is pre-trained for 50
epochs with early stop (patience of 10 epochs). For better convergence,
the model is trained with a decaying learning rate. The initial learning
rate is 0.001, which decayed until 0.00001 using ‘‘𝑟𝑒𝑑𝑢𝑐𝑒 𝑜𝑛 𝑝𝑙𝑎𝑡𝑒𝑎𝑢’’
method with a patient of 5 epochs. To train the network on each flood
site of our composed data (Table 1), we conducted 25 epochs of training
with an initial learning rate of 0.0001, which decayed until 0.000001
using ‘‘𝑟𝑒𝑑𝑢𝑐𝑒 𝑜𝑛 𝑝𝑙𝑎𝑡𝑒𝑎𝑢’’ with a patient of 3 epochs and early stop
with the patience of 5 epochs. With the help of pre-trained weights,
the network converged within 10 to 15 training epochs.

In the inference pipeline, a threshold TH is used on CosD values to
binarize the output change map COSINE_DIFF_MAP. The distribution of
the distance values in COSINE_DIFF_MAP is bimodal. The consolidated
data distribution of one random sample from each flood site is shown
below in Fig. 5. Where the values with distance close to 0 show
negligible change and higher values show significant change. After
analyzing the output data distribution we choose to use a threshold
of 0.5 i.e., CosD greater than 0.5 is categorized as change otherwise no
change.

5. Results

5.1. Compared methods

To demonstrate the benefits of the proposed CLVAE model, we
compare it with seven methods. The specifics of each method are as
follows.

1. Log-ratio is commonly used to highlight changes in pairs of
bitemporal SAR images (e.g. Hu and Ban 2014). Here, we cal-
culate log-ratio between the mean of four pre-flood images and
the post-flood image. Prior to computing the log-ratio, we use
Lee filter to suppress speckle noise from both images (Lee,
1981). Binary change maps from log-ratio are generated using
otsu (Otsu, 1979) and Yen’s thresholding methods (Yen et al.,
1995).

2. CVA is a popular CD method that generates both magnitude and
direction of change. In this work, we focus on the magnitude
of change. Therefore, we calculated only the magnitude change
using CVA and binarized it using otsu thresholding. Similar to

Fig. 5. Distribution plot of cosine distance output change map COSINE_DIFF_MAP. The
cosine distance is calculated between the pre and post-flood distribution inferenced
from the model.

log-ratio, CVA is calculated on the despeckled pre-flood mean
image and the post-flood image.

3. SCCN (Liu et al., 2016), is an unsupervised CD method. It is a
highly coupled convolutional network consisting of a Gaussian
and speckle noise model to reduce noise in the inputs and
calculate a change map.

4. cGAN (Niu et al., 2018), is an unsupervised conditional gener-
ative model that process 5 × 5 pixels of the input and generate
an intermediate denoised image. The change map is then calcu-
lated using the Euclidean distance between the denoised images
followed by fuzzy c-mean algorithm.

5. RaVAEn is an unsupervised method (Ržička et al., 2021) pro-
posed to detect changes in Sentinel-2 multispectral time series
images instead of SAR. For comparison, we adapt RaVAEn to
SAR time series data. RaVAEn used a simple VAE network with
a residual encoder trained using default VAE losses.

6. VAE, we implemented an encoder–decoder VAE network with
skip connections and maintained same depth as CLVAE. The
model is trained on the reconstruction task in an unsupervised
way using KL divergence and reconstruction loss. Change maps
are prepared using our proposed algorithm 1.

7. VAE+ConvLSTM, we implemented a VAE model on time se-
ries data. We used convolutional LSTM to accommodate the
temporal dimension effect. The model is also trained with re-
construction loss and KL divergence in an unsupervised manner.
The remaining architecture details are similar to the proposed
network.

The first four methods log-ratio, CVA, SCCN and cGAN are bi-temporal
change detection methods. To account some of the pre-image time
series data we are detecting changes between the mean image of pre-
flood time series and the post-flood image. Conversely, the last four
methods RaVAEn, VAE, VAE+ConvLSTM and CLVAE work directly on
time series input.

5.2. Quantitative results

For quantitative evaluation (Table 2), the performance of the pro-
posed CLVAE is compared with unsupervised traditional CD methods
(log-ratio, CVA), and unsupervised DL-based CD models (SCCN, cGAN
and RaVAEn). The results are also compared with ablated models VAE
and VAE+ConvLSTM.

On average, among all the compared models, CLVAE achieves the
best results. When compared to unsupervised CD methods (log-ratio,
CVA), CLVAE outperforms in all four average metrics. The lead in
recall ranges from 9%–25%, in precision from 14%–18%, in F1 score

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036356R. Yadav et al.

Table 2
Quantitative comparison of CLVAE with unsupervised non-DL and DL models. The first four methods take
mean of pre-images and post-flood image as two inputs, whereas the last four uses time series data. The
result metrics are percentage Recall, Precision, F1 score and IoU averaged over 5 runs.

Model

Log-Ratio
CVA
SCCN
cGAN

RaVAEn
VAE
VAE+ConvLSTM
CLVAE (ours)

Recall

Precision

F1

IoU

57.42
73.73
72.43 ± 1.08
80.16 ± 1.84

69.03 ± 3.23
78.66 ± 0.87
83.68 ± 1.56
82.38 ± 0.89

63.31
67.31
71.12 ± 3.71
57.39 ± 1.69

59.32 ± 2.16
69.10 ± 1.92
70.91 ± 1.46
81.11 ± 0.84

56.96
66.01
67.03 ± 3.19
62.86 ± 1.61

60.76 ± 1.80
71.50 ± 1.32
75.18 ± 1.51
81.40 ± 0.76

40.45
53.13
52.92 ± 3.01
51.48 ± 1.73

45.95 ± 1.78
58.23 ± 1.30
62.00 ± 1.53
70.14 ± 1.03

Fig. 6. Boxplot graph comparison of CLVAE performance with others.

from 15%–25%, and in IoU from 17%–30%. Compared to unsupervised
DL-based models, CLVAE exhibits a lead of 6%–21% in F1 score and
approximately 8%–18% in IoU. The cGAN shows the same recall as
CLVAE, and our implementation of VAE with convolutional LSTM gives
the best recall (1.3% better than CLVAE). However, both cGAN and
VAE with convolutional LSTM suffer from low precision, leading to low
F1 and IoU scores.

Further insights into the quantitative results are provided by Fig. 6,
Fig. 7 where the IoU results are visualized in boxplot and spider graphs.
In the boxplot, the 𝑥-axis represents the compared models and the 𝑦-
axis represents the percentage IoU score. Interestingly, CLVAE exhibits
the highest median IoU score with relatively low variance.

The spider graph compares the results on individual sites, where
the axis represents the evaluation sites and the numbers on all the
concentric circles represent the possible percentage IoU score from
0 at the center to 100 on the outermost circle. The outermost line
represents the best performing model and in the current scenario, it
is the proposed model CLVAE. On all flood sites, CLVAE yields the
best detection results except ‘Slovakia’ site, where both VAE with
convolutional LSTM and CLVAE are equally accurate.

5.3. Ablation

Ablation helps to investigate the contribution of the ConvLSTM
module and contrastive learning technique in the proposed CLVAE
model. The ‘BASE’ network refers to an encoder–decoder based VAE
reconstruction network with residual blocks and skip connections. The
average quantitative results of the ablation are shown in the last three
rows of Table 2. The results depict that ConvLSTM helps the network
to efficiently learn the feature representation resulting in better metric

scores. Contrastive learning further improved the scores by reducing
false detections (FN and FP). Although contrastive learning causes a
1.3% drop in recall, it gave approximately 6% better IoU with 8% better
precision, hence better detection results. Graph 6 gives further insight
into the ablation study. From left to right (VAE, VAE+ConvLSTM,
CLVAE), an increase in median value or an increase in the length of
the upper quartile indicates an increase in IoU score for at least 50%
of the sites.

5.4. Qualitative results

Four geographically different and challenging sites in Mekong, Bo-
livia, Australia and Bosnia are presented for a qualitative evaluation in
Figs. 8 and 9.

The first three rows of Fig. 8 show the detection results on ‘Mekong’
site. All CD models performed well on this site with few issues. Log-
ratio has the problem of grainy detections, whereas SCCN, CVA, VAE
and VAE+ConvLSTM missed some of the changed areas. RaVAEn de-
tected changes in 32 × 32 patches showing the ill-defined pixelated
change. The change map contains some false detection and also failed
to detect some parts of the changes shown in the reference map.
cGAN and CLVAE missed small flood streams, but detected most of
the flooded area. On average, all models detected the majority of
the flooded pixels on the ‘Mekong’ site. On ‘Bolivia’ site 8, the de-
tection results are comparatively less accurate. CVA and cGAN show
good detection results but suffer from speckle noise. Log-ratio missed
a significant part of the flooded area (change). The detection from
RaVAEn is also better but lacks details due to the coarse resolution
of the output change maps. VAE results show false detections which
seem to be refined by the time series data hence better scores by

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036357R. Yadav et al.

Fig. 7. Spider graph comparison showing sitewise IoU.

Table 3
Performance variation with respect to number of residual blocks in encoder.

Table 4
Performance variation with respect to distribution difference functions.

Residual blocks

1
2
3

Recall

81.58
82.38
80.88

Precision

77.50
81.11
75.04

F1

77.77
81.40
76.72

IoU

65.13
70.14
64.02

Distribution function

KLD/JSD/ED
CosD

Recall

81.75
82.38

Precision

77.62
81.11

F1

78.21
81.40

VAE model with convolutional LSTM. CLVAE with contrastive learning
techniques improved the results further by detecting missing flooded
areas. Compared to the other models CLVAE produced a clear and
speckle-free change map.

On the Bosnian site 9, the log-ratio, SCCN and VAE detected a good
part of the flooded area, but had many false detections in surrounding
areas. CVA and cGAN detection contain high speckle noise. RaVAEn
change map does not contain major false detection but failed to detect
most part of the changes shown in the reference map. VAE with
convolutional LSTM improved detection results with the help of time
series data and scored better. In CLVAE, the addition of contrastive
learning further improved the results. Although CLVAE could not detect
the flooded area with great success, it provided a significantly good
detection compared to others. The generated change map contains very
low false detection and does not suffer from speckle noise. The last
three rows of Fig. 9 show the detection results on the ‘Australia’ site.
Similar to ‘Mekong’ site, all CD models gave good detection on this
site as well. However, the proposed CLVAE gave the most accurate and
speckle free change map.

5.5. Performance variation with different configurations

The proposed CLVAE model is tested with different data and net-
work configurations, and the results are given in Tables 3, 4, 5 and 6. In
the encoder part of the proposed network, residual blocks downsample
the input data. We experiment with the number of residual blocks to
optimize the configuration and the best results are recorded with two
residual blocks 3.

In the inference pipeline, a distribution difference function is used
to generate the change map, we evaluated four distribution difference
functions: Kullback–Leibler Divergence (KLD), Jensen–Shannon Diver-
gence (JSD), Euclidean Distance (ED), and Cosine Distance (CosD). KLD
and JSD consider both mean and variance, while ED and CosD only
use the mean parameter. The average metrics from these functions are
summarized in Table 4. The similar values of KLD, JSD, and ED can be
attributed to two reasons, first is the assumption that the distribution

IoU

67.39
70.14

IoU

67.57
70.14
62.91

IoU

62.78
70.14
69.06

Table 5
Performance variation with respect to input patch size.

Patch size

8 × 8
16 × 16
32 × 32

Recall

82.00
82.38
80.16

Precision

76.32
81.11
73.04

F1

78.89
81.40
75.84

Table 6
Performance variation with respect to length (2, 4 and 8) of time series.

Length

2
4
8

Recall

77.45
82.38
83.96

Precision

72.51
81.11
76.48

F1

74.26
81.40
80.11

follows a Gaussian distribution with a variance of 1, and second is
that only the existence of change (binary) is considered, and not the
magnitude of the change. This condition equalizes the change maps
of KLD, JSD, and ED. On average, all distribution difference functions
yield good results, but CosD provided the best results and was therefore
chosen for the CLVAE configuration.

The results in Table 5 indicate that the performance of CLVAE
decreased when the patch size was increased from 16 to 32. This
decline is attributed to the model’s reliance on patch-wise average
distribution differences, which can nullify small changes when patches
are larger, leading to an inability to detect subtle variations. Ultimately,
bigger patches lead to less precise or smoothened change map. The
same effect is visible in the results where with 32 × 32 the recall
dropped by 1% while the precision dropped shows a signification
9% drop. Conversely, smaller patches (16 × 16) yield better results
due to their ability to capture more detailed information. However,
using further smaller patches of size 8 × 8 pixels may lead to a slight
drop in performance, as sometimes there is not enough neighborhood
information in such a small sample for the network to learn robust
features and speckle noise.

Results in Table 6 demonstrate that CLVAE’s performance improves
as the length of the input time series increases from two to four and
slightly decreases when the length is increased to eight. This decline

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036358R. Yadav et al.

Fig. 8. Qualitative comparison of CLVAE results with non-DL and DL models. The number below each change map corresponds percentage IoU score.

is attributed to frequent partial flooding occurring within the longer
duration. Notably, CLVAE achieves its best detection results when the
pre-images are free from flood anomalies. Nonetheless, the network is
still reliable to use for a longer time series at the cost of a small drop
in performance.

Table 7
Generalizability comparison of CLVAE with two supervised models ADS-Net and
DAUSAR on unseen CEMS sites.

Model

CLVAE
ADS-Net
DAUSAR

Recall

78.36
64.49
84.01

Precision

70.06
70.00
58.16

F1

72.83
62.28
64.20

IoU

58.39
49.05
51.21

5.6. Generalizability

This generalizability of CLVAE is tested by comparing the re-
sults with two supervised models ADS-Net (Wang et al., 2021) and
DAUSAR (Yadav et al., 2022a) on four unseen sites. The models are
trained on floods from Sen1Floods11 dataset and tested on four CEMS
sites ‘Bosnia’, ‘Australia’, ‘Scotland’ and ‘Germany’. The average results
on the four sites are given in Table 7.

Due to domain shift, the supervised models demonstrated less accu-
rate detection compared to our proposed unsupervised model, CLVAE.
On average, CLVAE exhibits superior scores. Notably, the supervised
model DAUSAR exhibits a high recall but significantly low precision,
indicating a substantial number of false positives. ADS-Net displays

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)1036359R. Yadav et al.

Fig. 9. Qualitative comparison of CLVAE results with non-DL and DL models. The number below each change map corresponds percentage IoU score.

lower recall and lower precision compared to CLVAE, with a high
occurrence of both false positives and false negatives. These false
detections are evident in the qualitative results, as shown in Fig. 10.
While there is a decrease in CLVAE performance when inferring on
unseen sites, the drop remains relatively modest. Consequently, the
change detection capabilities of CLVAE retain its generalizability across
geographically distinct and previously unobserved sites.

6. Discussion and conclusion

In this work, we propose a novel unsupervised CD model named
CLVAE, which aims to learn the spatiotemporal correlations between
Sentinel-1 SAR time series. Our model can generate discriminative
features and robust latent representations by leveraging reconstruction

and contrastive losses. Using the latent representation, our proposed
algorithm can produce accurate pixel-wise change maps.

We performed a detailed evaluation to understand the flood detec-
tion results on all the sites (Section 5.2 and Section 5.4) and observed
that our proposed model CLVAE gave significantly improved flood
detection on all the sites. However, compared to other sites, the ac-
curacy (IoU) is lower for ‘Spain’, ‘Somalia’ and ‘Scotland’ flood sites.
We performed an in-depth investigation to identify distinct factors
contributing to these discrepancies. The low accuracy areas in ‘Spain’
floods are particularly those with tree plantations like olives, avocados,
and mangoes, which are not easily distinguishable in the S1 post-
event image and therefore are not detected by the CLVAE model. In
regions characterized by sparse plantations, forests and dry soil, radi-
ation scatter in various directions, involving contributions from both

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)10363510R. Yadav et al.

Fig. 10. Generalizability Test: Comparison of change map from ADS-Net, DAUSAR and CLVAE on unseen sites.

the tree canopy and the ground surface. However, when the ground
becomes flooded, a predominant shift occurs in the direction of energy
scattering. The now flooded water returns low backscatter whereas
the sparse trees show enhancement in double-bounce effect which is
influenced by the interaction of radar signals with flooded terrain
and tree structures, introducing complexities in the detection process
(less dark areas), particularly in discerning flooded areas within these
sparse tree plantations. We see similar issues in the sparsely forested
flood site of ‘Somalia’. In ‘Scotland’ flood site, the discrepancies arise
from potential shortcomings in label production, where certain clearly
flooded areas in post-event Sentinel-1 SAR images are not reflected in
the provided labels.

In conclusion, despite the mentioned limitations, our proposed
CLVAE model consistently outperforms existing non-DL and DL models.
It achieves an average IoU of 70% and an average F1 score of 81%,
surpassing the compared models by a minimum of 6% in F1 and 8% in
IoU score. Notably, our CLVAE model efficiently addresses the domain
shift problem inherent in supervised models, demonstrating better
generalizability (58.39% IoU) on unseen sites compared to supervised
models like DAUSAR (51.21% IoU) and ADS-Net (49.05% IoU). Addi-
tionally, our CLVAE model is memory-efficient, has low computation
time (enabling faster training and inference), and is cost-effective in
terms of data preparation as it does not require annotations.

In the future, we plan to extend our model’s capabilities to detect
other disaster events such as wildfires and landslides. We also plan
to utilize pre-disaster optical data. SAR and optical sensors capture
specific features of the scene. Although post-disaster optical data is
often partially hindered by clouds or smoke (Prudente et al., 2020)
affecting the impact assessment capability, we can still utilize pre-
disaster optical data to learn the contextual information (Yadav et al.,
2023).

CRediT authorship contribution statement

Ritu Yadav: Conceptualization, Data curation, Formal analysis, In-
vestigation, Methodology, Validation, Visualization, Writing – original
draft, Writing – review & editing. Andrea Nascetti: Methodology,
Supervision, Validation, Writing – review & editing. Hossein Azizpour:
Supervision, Writing – review & editing, Methodology, Validation.
Yifang Ban: Funding acquisition, Project administration, Resources,
Software, Supervision, Writing – review & editing.

Declaration of competing interest

The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.

Data availability

Data will be made available on request.

Acknowledgments

This research is part of the EO-AI4GlobalChange project funded by

Digital Futures.

References

Anusha, N., Bharathi, B., 2020. Flood detection and flood mapping using multi-temporal
synthetic aperture radar and optical data. Egypt. J. Remote Sens. Space Sci. 23 (2),
207–219.

Asokan, A., Anitha, J., 2019. Change detection techniques

for

remote sensing

applications: a survey. Earth Sci. Inform. 12 (2), 143–160.

Bonafilia, D., Tellman, B., Anderson, T., Issenberg, E., 2020. Sen1Floods11: a georef-
erenced dataset to train and test deep learning flood algorithms for Sentinel-1.
In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition Workshops. Vol. 180. CVPRW, IEEE, pp. 163–173.

Boryan, C.G., Yang, Z., Sandborn, A., Willis, P., Haack, B., 2018. Operational
agricultural flood monitoring with Sentinel-1 synthetic aperture radar. In: IEEE
International Geoscience and Remote Sensing Symposium.
IEEE, pp.
5831–5834.

IGARSS,

Cai, L., Gao, H., Ji, S., 2019. Multi-stage variational auto-encoders for coarse-to-fine
image generation. In: Proceedings of the 2019 SIAM International Conference on
Data Mining. SIAM, pp. 630–638.

Caron, M., Bojanowski, P., Joulin, A., Douze, M., 2018. Deep clustering for unsuper-
vised learning of visual features. In: Proceedings of the European Conference on
Computer Cision. ECCV, pp. 132–149.

CEMS, 2022. Copernicus emergency management services,

list of actvations. URL

https://emergency.copernicus.eu/mapping/copernicus-emergency-management-
service#zoom=2&lat=31.47858&lon=7.20923&layers=0BT00.
September 2023).

(Accessed

30

Chen, X., Fan, H., Girshick, R., He, K., 2020a. Improved baselines with momentum

contrastive learning. arXiv preprint arXiv:2003.04297.

Chen, T., Kornblith, S., Norouzi, M., Hinton, G., 2020b. A simple framework for
International Conference on

In:

contrastive learning of visual representations.
Machine Learning. ICML, PMLR, pp. 1597–1607.

Cian, F., Marconcini, M., Ceccato, P., 2018. Normalized difference flood index for rapid
flood mapping: Taking advantage of EO big data. Remote Sens. Environ. (RSE) 209,
712–730.

CRED, 2022. 2021 Disasters in numbers. URL https://reliefweb.int/report/world/2021-
disasters-numbers#:~:text=In%202021%2C%20a%20total%20of,across%20the%
202001%2D2020%20period. (Accessed 30 September 2023).

Dai, B., Wang, Z., Wipf, D., 2020. The usual suspects? Reassessing blame for VAE
posterior collapse. In: International Conference on Machine Learning. ICML, PMLR,
pp. 2313–2322.

Dong, H., Ma, W., Jiao, L., Liu, F., Li, L., 2021a. A multiscale self-attention deep
clustering for change detection in SAR images. IEEE Trans. Geosci. Remote Sens.
(TGRS) 60, 1–16.

Dong, N., Maggioni, M., Yang, Y., Pérez-Pellitero, E., Leonardis, A., McDonagh, S.,
2021b. Residual contrastive learning for joint demosaicking and denoising. arXiv
preprint arXiv:2106.10070.

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)10363511R. Yadav et al.

Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C.,
Avila Pires, B., Guo, Z., Gheshlaghi Azar, M., et al., 2020. Bootstrap your
own latent-a new approach to self-supervised learning. In: Advances in Neural
Information Processing Systems. Vol. 33. pp. 21271–21284.

Hadsell, R., Chopra, S., LeCun, Y., 2006. Dimensionality reduction by learning an
invariant mapping. In: IEEE Computer Society Conference on Computer Vision and
Pattern Recognition. Vol. 2. CVPR, IEEE, pp. 1735–1742.

Hu, H., Ban, Y., 2014. Unsupervised change detection in multitemporal SAR images
over large urban areas. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. (JSTAR)
7 (8), 3248–3261.

Karamvasis, K., Karathanassi, V., 2021. FLOMPY: An open-source toolbox for floodwater

mapping using sentinel-1 intensity time series. Water 13 (21), 2943.

Kingma, D.P., Welling, M., 2013. Auto-encoding variational bayes. CoRR abs/1312.6114

(2013). arXiv preprint arXiv:1312.6114. 482.

Saha, S., Ebel, P., Zhu, X.X., 2021. Self-supervised multisensor change detection. IEEE

Trans. Geosci. Remote Sens. 60, 1–10.

Schlaffer, S., Matgen, P., Hollaus, M., Wagner, W., 2015. Flood detection from multi-
temporal SAR data using harmonic analysis and change detection. Int. J. Appl.
Earth Obs. Geoinform. (JAG) 38, 15–24.

Tuia, D., Persello, C., Bruzzone, L., 2016. Domain adaptation for the classification of
remote sensing data: An overview of recent advances. IEEE Geosci. Remote Sens.
Mag. 4 (2), 41–57.

Wang, D., Chen, X., Jiang, M., Du, S., Xu, B., Wang, J., 2021. ADS-Net: An Attention-
Based deeply supervised network for remote sensing image change detection. Int.
J. Appl. Earth Obs. Geoinform. (JAG) 101, 102348.

Wang, J., Gao, F., Dong, J., Du, Q., Li, H.-C., 2022a. Change detection from synthetic
aperture radar images via dual path denoising network. IEEE J. Sel. Top. Appl.
Earth Obs. Remote Sens. (JSTAR) 15, 2667–2680.

Krinidis, S., Chatzis, V., 2010. A robust fuzzy local information C-means clustering

Wang, S., Zhang, L., Chen, W., Wang, F., Li, H., 2022b. Refining pseudo labels for

algorithm. IEEE Trans. Image Process. 19 (5), 1328–1337.

unsupervised domain adaptive re-identification. Knowl.-Based Syst. 242, 108336.

Lee, J.-S., 1981. Speckle analysis and smoothing of synthetic aperture radar images.

Comput. Graph. Image Process. 17 (1), 24–32.

Liu, J., Gong, M., Qin, K., Zhang, P., 2016. A deep convolutional coupling network for
change detection based on heterogeneous optical and radar images. IEEE Trans.
Neural Netw. Learn. Syst. 29 (3), 545–559.

Luppino, L.T., Hansen, M.A., Kampffmeyer, M., Bianchi, F.M., Moser, G., Jenssen, R.,
Anfinsen, S.N., 2022. Code-aligned autoencoders for unsupervised change detection
in multimodal remote sensing images. IEEE Trans. Neural Netw. Learn. Syst..
Lv, Z., Huang, H., Li, X., Zhao, M., Benediktsson, J.A., Sun, W., Falco, N., 2022.
Land cover change detection with heterogeneous remote sensing images: Review,
progress, and perspective. Proc. IEEE.

Niu, X., Gong, M., Zhan, T., Yang, Y., 2018. A conditional adversarial network for
change detection in heterogeneous images. IEEE Geosci. Remote Sens. Lett. 16 (1),
45–49.

Otsu, N., 1979. A threshold selection method from gray-level histograms. IEEE Trans.

Syst. Man Cybern. 9 (1), 62–66.

Prudente, V.H., Sanches,

I., Adami, M., Skakun, S., Oldoni, L.V., Xaud, H.A.M.,
Xaud, M.R., Zhang, Y., 2020. SAR data for land use land cover classification in a
tropical region with frequent cloud cover. In: IGARSS 2020-2020 IEEE International
Geoscience and Remote Sensing Symposium. IEEE, pp. 4100–4103.

Yadav, R., Nascetti, A., Ban, Y., 2022a. Attentive dual stream siamese u-net for flood
detection on multi-temporal sentinel-1 data. In: IEEE International Geoscience and
Remote Sensing Symposium. IGARSS, IEEE, pp. 5222–5225.

Yadav, R., Nascetti, A., Ban, Y., 2022b. Deep attentive fusion network for flood
detection on uni-temporal Sentinel-1 data. Front. Remote Sens. 3, 1060144.
Yadav, R., Nascetti, A., Ban, Y., 2023. Context-aware change detection with semi-
IEEE International Geoscience and Remote Sensing
IGARSS, pp. 5754–5757. http://dx.doi.org/10.1109/IGARSS52108.

In:

supervised learning.
Symposium.
2023.10281798.

Yan, P., He, F., Yang, Y., Hu, F., 2020. Semi-supervised representation learning for
remote sensing image classification based on generative adversarial networks. IEEE
Access 8, 54135–54144.

Yen, J.-C., Chang, F.-J., Chang, S., 1995. A new criterion for automatic multilevel

thresholding. IEEE Trans. Image Process. 4 (3), 370–378.

Yu, X., Wu, X., Luo, C., Ren, P., 2017. Deep learning in remote sensing scene classi-
fication: a data augmentation enhanced convolutional neural network framework.
GISci. Remote Sens. 54 (5), 741–758.

Zhan, T., Gong, M., Jiang, X., Li, S., 2018. Log-based transformation feature learning
for change detection in heterogeneous images. IEEE Geosci. Remote Sens. Lett. 15
(9), 1352–1356.

Ren, C., Wang, X., Gao, J., Zhou, X., Chen, H., 2020. Unsupervised change detection in
satellite images with generative adversarial network. IEEE Trans. Geosci. Remote
Sens. (TGRS) 59 (12), 10047–10061.

Zhao, B., Sui, H., Liu, J., 2023. Siam-DWENet: Flood inundation detection for SAR
imagery using a cross-task transfer siamese network. Int. J. Appl. Earth Obs.
Geoinform. (JAG) 116, 103132.

Ržička, V., Vaughan, A., De Martini, D., Fulton, J., Salvatelli, V., Bridges, C., Mateo-
Garcia, G., Zantedeschi, V., 2021. Unsupervised change detection of extreme events
using ML on-board. arXiv preprint arXiv:2111.02995.

Zhou, W., Newsam, S., Li, C., Shao, Z., 2018. PatternNet: A benchmark dataset for
performance evaluation of remote sensing image retrieval. ISPRS J. Photogramm.
Remote Sens. 145, 197–209.

InternationalJournalofAppliedEarthObservationandGeoinformation126(2024)10363512